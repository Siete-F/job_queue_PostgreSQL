# Fluentd logs (also failures while parsings of other logs become a `fluent.` log) must also be json and saved in the elasticsearch db.
<system>
    <log>
      format json  # apperently does not matter for elasticsearch
      time_format %Y-%m-%dT%H:%M:%S.%L
    </log>
</system>

<source>
    @type forward
    port 24224
</source>

#<filter fluent.**>
#  @type record_transformer
#  enable_ruby
#  <record>
#    timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%L')}
#    #timestam ${record["time"].strftime('%Y-%m-%dT%H:%M:%S.%L')}
#  </record>
#</filter>

<filter es.**>
  @type parser
  format json
  key_name log  # The name 'log' is defined by docker. See "https://docs.docker.com/config/containers/logging/fluentd/" for what the docker fluentd logger sends over: {source: "stdout", log: "The message", ...)
  reserve_data true
  #remove_key_name_field true  # If enabled, would remove 'log' once it is parsed (no data, except for it's source, gets lost)
</filter>

# The first match will be used!!! don't use multiple match statements which overlap
<match es.**>
    @type elasticsearch
    # @log_level trace  # log everything that enters this match (if 'match **', that would be everything)
    # comma seperated list of hosts host1:port1,host2:port2 etc.
    host "#{ENV['ELASTICSEARCH_HOST']}"  # elasticsearch
    port "#{ENV['ELASTICSEARCH_PORT']}"  # 9200
    log_es_400_reason true  #https://github.com/uken/fluent-plugin-elasticsearch#log_es_400_reason
    index_name fluentd.${tag}
    <buffer>
        flush_interval 1s
        flush_thread_count 2
    </buffer>
</match>

# `fluent.warn` and `fluent.info`
<match fluent.**>
    @type elasticsearch
    # comma seperated list of hosts host1:port1,host2:port2 etc.
    host elasticsearch
    port 9200
    log_es_400_reason true
    index_name ${tag}
    <buffer>
        flush_interval 1s
        flush_thread_count 2
    </buffer>
</match>

<match file.**>
    @type file
    path /fluentd/log/fluentd-test-output.log
    append true
    add_path_suffix false
    
    # With JSON
    # {"worker":0,"message":"fluentd worker is now running worker=0","tag":"fluent.info","date":"2019-10-24 14:02:24"}
    # No JSON:
    # 2019-10-24T13:46:18+00:00       fluent.info     {"worker":0,"message":"fluentd worker is now running worker=0","tag":"fluent.info","date":"2019-10-24 13:46:18"}        
    #<format>
    #    @type json
    #</format>
    <inject>
        tag_key tag
        time_key date
        time_type string
        time_format %F %T
    </inject>
    <buffer []>
        @type memory
        chunk_limit_records 1
        retry_max_times 0
    </buffer>
</match>


<match stdout.** **>
    @type stdout
    <buffer>
        flush_interval 1s
    </buffer>
</match>